{
    "experiment_name": "baseline",
    "model": {
      "LSTM_unit_size": 64,
      "dense_unit_size": 32,
      "dropout_rate": 0.3,
      "learning_rate": 0.001,
      "early_stopping_patience":4
    },
    "training": {
      "batch_size": 64,
      "epochs": 60,
      "sequence_length": 20,
      "step": 1
    }
  }